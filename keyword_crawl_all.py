# keyword_crawl_all.py - å•ç«™ç‚¹åˆå¹¶å­˜å‚¨ç‰ˆï¼Œå®ç°åŒä¸€ç«™ç‚¹åˆ†é¡µæŠ“å–æ•°æ®æ•´åˆåˆ°åŒä¸€ä¸ª CSV

import pandas as pd
import os
from datetime import datetime
from urllib.parse import quote
from spider import fetcher, utils
from spider import parser_search

save_folder = "data/keyword_crawl_all"
os.makedirs(save_folder, exist_ok=True)

sites_df = pd.read_csv("config/sites_to_crawl_full.csv")
sites_df = sites_df[sites_df['enable'] == 1]

keyword = input("è¯·è¾“å…¥è¦æŠ“å–çš„å…³é”®è¯: ").strip()
keyword_encoded = quote(keyword)
today_str = datetime.now().strftime("%Y%m%d")

for idx, row in sites_df.iterrows():
    site_name = row['site_name']
    search_template = row['search_template']
    parser_name = row['parser']

    print(f"\nğŸš€ æ­£åœ¨æŠ“å–ç«™ç‚¹: {site_name}ï¼Œå…³é”®è¯: {keyword} (å…¨é‡åˆ†é¡µ)")

    page = 1
    start = 0
    cursor = "*"
    max_empty_pages = 3
    empty_pages = 0
    all_data = []

    while True:
        url = search_template.format(keyword=keyword_encoded, page=page, start=start, cursor=cursor)
        print(f"ğŸŒ æ­£åœ¨æŠ“å–: {url}")

        html = fetcher.fetch_url(url)
        if html is None:
            print(f"âš ï¸ è·³è¿‡ {url}ï¼Œè¯·æ±‚å¤±è´¥ã€‚")
            empty_pages += 1
        else:
            parse_function = getattr(parser_search, parser_name, None)
            if parse_function is None:
                print(f"âŒ æœªæ‰¾åˆ°è§£æå‡½æ•°: {parser_name}")
                break

            page_data = parse_function(html, url=url)
            if page_data:
                all_data.extend(page_data)
                print(f"âœ… æœ¬é¡µæŠ“å– {len(page_data)} æ¡ï¼Œæ€»è®¡ {len(all_data)} æ¡")
                empty_pages = 0  # é‡ç½®
            else:
                print(f"âš ï¸ æœ¬é¡µæ— æ•°æ®ã€‚")
                empty_pages += 1

        # åˆ†é¡µæ¨è¿›
        page += 1
        start += 50

        if empty_pages >= max_empty_pages:
            print(f"âœ… è¿ç»­ {max_empty_pages} é¡µæ— æ•°æ®ï¼Œåœæ­¢ {site_name} æŠ“å–ã€‚")
            break

    if all_data:
        df = pd.DataFrame(all_data)
        dst_name = f"{site_name}_{keyword.replace(' ', '_')}_{today_str}.csv"
        dst_path = os.path.join(save_folder, dst_name)
        df.to_csv(dst_path, index=False)
        print(f"\nâœ… å·²åˆå¹¶ä¿å­˜ {len(df)} æ¡æ•°æ®è‡³: {dst_path}")
    else:
        print(f"âŒ {site_name} æœªæŠ“å–åˆ°ä»»ä½•æ•°æ®ï¼Œæœªç”Ÿæˆæ–‡ä»¶ã€‚")

print("\nğŸ‰ æ‰€æœ‰å…³é”®è¯å†å²åˆ†é¡µæŠ“å–å¹¶åˆå¹¶å®Œæˆã€‚")